{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import rand\n",
    "import skimage as sm\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.util import img_as_float\n",
    "from skimage import transform\n",
    "from skimage.filters import gaussian as ski_gaussian\n",
    "from pylab import ginput\n",
    "from scipy.signal import convolve, convolve2d, correlate2d\n",
    "from scipy.signal import  gaussian as scipy_gaussian\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(os.getcwd()+\"\\Mats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several plotting tools\n",
    "\n",
    "def plotGray(image): #Plots an image in gray scale\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image,cmap=\"gray\")\n",
    "\n",
    "def plotRGB(image): #Plots an image in RGB color\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image,cmap=\"jet\")\n",
    "\n",
    "def blend(images,weights): #Blending of x images\n",
    "    # Input\n",
    "    # images: list\n",
    "    # weights: list\n",
    "    imgBlend = np.zeros(images[0].shape,dtype=images[0].dtype)\n",
    "    print(imgBlend.dtype,images[0].dtype,weights[0])\n",
    "    for img,W in zip(images,weights):\n",
    "        imgBlend += (img*W).astype(images[0].dtype)\n",
    "    return imgBlend\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pixel: X=5, Y=12\n"
     ]
    }
   ],
   "source": [
    "image = np.random.rand(20, 20)\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.xticks(np.arange(0, 20, 1))\n",
    "plt.yticks(np.arange(0, 20, 1))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "coords = ginput(n=1, timeout=5, show_clicks=True)\n",
    "x, y = map(round, coords[0])\n",
    "image[y, x] = 0\n",
    "plt.clf()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.xticks(np.arange(0, 20, 1))\n",
    "plt.yticks(np.arange(0, 20, 1))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "print(\"Selected pixel: X={}, Y={}\".format(x, y))\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(\"cameraman.tif\")\n",
    "bitImage = []\n",
    "for i in range(255):\n",
    "    bitImage.append(np.bitwise_and(image,i+1))\n",
    "\n",
    "bitImage = np.asarray(bitImage)\n",
    "plt.imshow(np.sum(bitImage,axis=0),cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.imshow(bitImage[0],cmap=\"gray\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBGtoHSVDisplay(image):\n",
    "    hsv_image = sm.color.rgb2hsv(image)\n",
    "    hue_image = hsv_image[:,:,0]\n",
    "    sat_image = hsv_image[:,:,1]\n",
    "    value_image = hsv_image[:,:,2]\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Hue\")\n",
    "    plt.axis('off')\n",
    "    plt.imshow(hue_image,cmap=\"hsv\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Saturation\")\n",
    "    plt.imshow(sat_image,cmap=\"hsv\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Value\")\n",
    "    plt.axis('off')\n",
    "    plt.imshow(value_image,cmap=\"hsv\")\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "image = imread(\"monster.jpg\")\n",
    "\n",
    "RBGtoHSVDisplay(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(images,weights):\n",
    "    imgBlend = np.zeros(images[0].shape,dtype=np.float64)\n",
    "    for img,W in zip(images,weights):\n",
    "        if img.dtype == np.uint8:\n",
    "            img = img/np.iinfo(img.dtype).max\n",
    "        imgBlend += (img*W).astype(np.float64) \n",
    "    return imgBlend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = imread(\"toycars1.png\")\n",
    "img2 = imread(\"toycars2.png\")\n",
    "img3 = imread(\"toycars3.png\")\n",
    "imageblend = blend([img1,img2,img3],[0.2,0.5,0.3])\n",
    "plotRGB(imageblend)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBGtoGray(image):\n",
    "    return 0.2989*image[:,:,0] + 0.5870*image[:,:,1] + 0.1140*image[:,:,2]\n",
    "\n",
    "image = imread(\"monster.jpg\")\n",
    "imageGray = RBGtoGray(image)\n",
    "\n",
    "plt.figure(1)\n",
    "plotGray(imageGray)\n",
    "plt.figure(2)\n",
    "plotRGB(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769 1009 3\n"
     ]
    }
   ],
   "source": [
    "print(image.shape[0],image.shape[1],image.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize test rows low\n",
    "image = imread(\"monster.jpg\")\n",
    "plt.subplot(3,1,1)\n",
    "imgResize = transform.resize(image,(700,image.shape[1],image.shape[2]))\n",
    "plotRGB(imgResize)\n",
    "plt.subplot(3,1,2)\n",
    "imgResize = transform.resize(image,(300,image.shape[1],image.shape[2]))\n",
    "plotRGB(imgResize)\n",
    "plt.subplot(3,1,3)\n",
    "imgResize = transform.resize(image,(100,image.shape[1],image.shape[2]))\n",
    "plotRGB(imgResize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize test rows low\n",
    "image = imread(\"monster.jpg\")\n",
    "plt.subplot(1,3,1)\n",
    "imgResize = transform.resize(image,(image.shape[1],1000,image.shape[2]))\n",
    "plotRGB(imgResize)\n",
    "plt.subplot(1,3,2)\n",
    "imgResize = transform.resize(image,(image.shape[1],500,image.shape[2]))\n",
    "plotRGB(imgResize)\n",
    "plt.subplot(1,3,3)\n",
    "imgResize = transform.resize(image,(image.shape[1],300,image.shape[2]))\n",
    "plotRGB(imgResize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize test for blending\n",
    "image = imread(\"monster.jpg\")\n",
    "img1 = imread(\"toycars1.png\")\n",
    "img2 = imread(\"toycars2.png\")\n",
    "img3 = imread(\"toycars3.png\")\n",
    "\n",
    "\n",
    "imgResize = transform.resize(image,img1.shape)\n",
    "plt.subplot(1,3,1)\n",
    "plotRGB(image)\n",
    "plt.subplot(1,3,2)\n",
    "plotRGB(imgResize)\n",
    "plt.subplot(1,3,3)\n",
    "imageblend = blend([img1,img2,img3,imgResize],[0.25,0.25,0.25,0.25])\n",
    "plotRGB(imageblend)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(72.66017316017317, 394.9545454545454), (191.7077922077922, 394.9545454545454), (135.90097402597402, 174.55357142857142), (140.85227272727272, 174.87824675324674)]\n",
      "119.0 5.0\n"
     ]
    }
   ],
   "source": [
    "image = imread(\"railway.png\")\n",
    "\n",
    "plotRGB(image)\n",
    "coords = ginput(n=4, timeout=0, show_clicks=True)\n",
    "print(coords)\n",
    "for i,coord in enumerate(coords):\n",
    "    coords[i] = np.array(np.round(coord))\n",
    "\n",
    "print(np.linalg.norm(coords[0]-coords[1]),np.linalg.norm(coords[2]-coords[3]))\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m in pixel for foreground: 47.6 \n",
      "2m in pixel for background: 2.0\n"
     ]
    }
   ],
   "source": [
    "fg1m = 119/2.5\n",
    "bg1m = 5/2.5\n",
    "\n",
    "print(\"2m in pixel for foreground:\",fg1m,\"\\n2m in pixel for background:\",bg1m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get abslute distance of the items from the camera one needs 3 things: The size of the object in real life (2.5m), the size in pixels (found using software), and the focal lenght of the camera. This would be the distance between the pinhole and the detector. If you have all these parameters, you would be able to gauge the distance between an object in the image and the camera."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = img_as_float(imread(\"cell.tif\"))\n",
    "img2 = img_as_float(imread(\"cameraman.tif\"))\n",
    "\n",
    "img1Resize = transform.resize(img1,img2.shape)\n",
    "img2Resize = transform.resize(img2,img1.shape)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(2,2,1)\n",
    "plotGray(img1)\n",
    "plt.subplot(2,2,2)\n",
    "plotGray(img2Resize)\n",
    "plt.subplot(2,2,3)\n",
    "plotGray(img1Resize)\n",
    "plt.subplot(2,2,4)\n",
    "plotGray(img2)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.subplot(2,2,1)\n",
    "plotGray(img1+img2Resize)\n",
    "plt.subplot(2,2,2)\n",
    "plotGray(img2Resize+img1)\n",
    "plt.subplot(2,2,3)\n",
    "plotGray(np.clip(img1+img2Resize,0,1))\n",
    "plt.subplot(2,2,4)\n",
    "plotGray(np.clip(img2Resize+img1,0,1))\n",
    "\n",
    "plt.figure(3)\n",
    "plt.subplot(2,2,1)\n",
    "plotGray(img1-img2Resize)\n",
    "plt.subplot(2,2,2)\n",
    "plotGray(img2Resize-img1)\n",
    "plt.subplot(2,2,3)\n",
    "plotGray(np.clip(img1-img2Resize,0,1))\n",
    "plt.subplot(2,2,4)\n",
    "plotGray(np.clip(img2Resize-img1,0,1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec2cab1a05e3ec8eaefb3e4ce76e6348cc4fe9980ee22546d6543ad5f462b7a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
